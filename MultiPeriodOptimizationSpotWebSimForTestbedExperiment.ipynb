{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('.'))\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "sys.path.insert(0, os.path.abspath('../cvxportfolio'))\n",
    "\n",
    "\n",
    "import cvxportfolio.Modsimulatorow as ms\n",
    "from cvxportfolio import Modpoliciesoldworking as mp\n",
    "import cvxportfolio.Modcostsoldworking as mc\n",
    "import cvxportfolio.Modrisksoldworking as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Index([u'r5d.24xlarge', u'r5.4xlarge', u'r4.4xlarge'], dtype='object')\n",
      "['r5d.24xlarge', 'r5.4xlarge', 'r4.4xlarge'] 3\n",
      "                       r5d.24xlarge      r5.4xlarge      r4.4xlarge\n",
      "2018-08-30 22:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-06 17:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-19 23:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-20 22:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 00:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 01:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 05:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 06:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 08:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 09:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 10:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 11:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 12:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 13:00:00  1000000.000000  1000000.000000  1000000.000000\n",
      "2018-09-23 14:00:00        0.000891  1000000.000000  1000000.000000\n",
      "2018-09-23 15:00:00        0.000891  1000000.000000  1000000.000000\n",
      "2018-09-23 16:00:00        0.000891  1000000.000000  1000000.000000\n",
      "2018-09-23 17:00:00        0.000891  1000000.000000  1000000.000000\n",
      "2018-09-23 18:00:00        0.000891  1000000.000000  1000000.000000\n",
      "2018-09-23 19:00:00        0.000891  1000000.000000  1000000.000000\n",
      "2018-09-23 20:00:00        0.000891  1000000.000000  1000000.000000\n",
      "2018-09-23 21:00:00        0.000999        0.001064  1000000.000000\n",
      "2018-09-23 22:00:00        0.000999        0.000891  1000000.000000\n",
      "2018-09-23 23:00:00        0.000902        0.000891  1000000.000000\n",
      "2018-09-24 00:00:00        0.000902        0.000891  1000000.000000\n",
      "2018-09-24 01:00:00        0.000902        0.000891  1000000.000000\n",
      "2018-09-24 02:00:00        0.000902        0.001056  1000000.000000\n",
      "2018-09-24 03:00:00        0.000902        0.001056  1000000.000000\n",
      "2018-09-24 04:00:00        0.000902        0.001056  1000000.000000\n",
      "2018-09-24 05:00:00        0.000902        0.001056  1000000.000000\n",
      "...                             ...             ...             ...\n",
      "2018-11-21 19:00:00        0.002181        0.001102        0.001192\n",
      "2018-11-21 20:00:00        0.000891        0.000970        0.001007\n",
      "2018-11-21 21:00:00        0.000891        0.001277        0.001050\n",
      "2018-11-21 22:00:00        0.000891        0.001432        0.001170\n",
      "2018-11-21 23:00:00        0.000891        0.001432        0.002119\n",
      "2018-11-22 00:00:00        0.000891        0.001432        0.002119\n",
      "2018-11-22 01:00:00        0.000891        0.001432        0.001192\n",
      "2018-11-22 02:00:00        0.000891        0.001287        0.001004\n",
      "2018-11-22 03:00:00        0.000891        0.000971        0.001169\n",
      "2018-11-22 04:00:00        0.000891        0.001442        0.002085\n",
      "2018-11-22 05:00:00        0.000891        0.001442        0.002085\n",
      "2018-11-22 06:00:00        0.000891        0.001442        0.000946\n",
      "2018-11-22 07:00:00        0.000891        0.001442        0.001189\n",
      "2018-11-22 08:00:00        0.003417        0.001097        0.001001\n",
      "2018-11-22 09:00:00        0.003417        0.001097        0.001044\n",
      "2018-11-22 10:00:00        0.003417        0.001432        0.001044\n",
      "2018-11-22 11:00:00        0.003417        0.001432        0.000943\n",
      "2018-11-22 12:00:00        0.003417        0.001432        0.001191\n",
      "2018-11-22 13:00:00        0.003263        0.001098        0.001191\n",
      "2018-11-22 14:00:00        0.003263        0.001098        0.001170\n",
      "2018-11-22 15:00:00        0.003263        0.001411        0.001039\n",
      "2018-11-22 16:00:00        0.003263        0.001288        0.001039\n",
      "2018-11-22 17:00:00        0.003263        0.001288        0.001197\n",
      "2018-11-22 18:00:00        0.003263        0.000891        0.001197\n",
      "2018-11-22 19:00:00        0.003263        0.000891        0.000993\n",
      "2018-11-22 20:00:00        0.003230        0.001099        0.000993\n",
      "2018-11-22 21:00:00        0.003230        0.001099        0.001163\n",
      "2018-11-22 22:00:00        0.003230        0.001375        0.001986\n",
      "2018-11-22 23:00:00        0.003230        0.001277        0.001213\n",
      "2018-11-23 00:00:00        0.003230        0.001277        0.001213\n",
      "\n",
      "[1465 rows x 3 columns]\n",
      "DatetimeIndex(['2018-08-30 22:00:00', '2018-09-06 17:00:00',\n",
      "               '2018-09-19 23:00:00', '2018-09-20 22:00:00',\n",
      "               '2018-09-23 00:00:00', '2018-09-23 01:00:00',\n",
      "               '2018-09-23 05:00:00', '2018-09-23 06:00:00',\n",
      "               '2018-09-23 08:00:00', '2018-09-23 09:00:00',\n",
      "               ...\n",
      "               '2018-11-22 15:00:00', '2018-11-22 16:00:00',\n",
      "               '2018-11-22 17:00:00', '2018-11-22 18:00:00',\n",
      "               '2018-11-22 19:00:00', '2018-11-22 20:00:00',\n",
      "               '2018-11-22 21:00:00', '2018-11-22 22:00:00',\n",
      "               '2018-11-22 23:00:00', '2018-11-23 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=1465, freq=None)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload                              \n",
    "#autoreload reloads modules automatically before entering the execution of code\n",
    "%autoreload 2                                      \n",
    "#autoreload reloads modules automatically before entering the execution of code typed at the IPython prompt.\n",
    "%matplotlib inline                              \n",
    "#Put the plots inline in the notebook\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import cvxpy as cvx\n",
    "from cvxportfolio.constraintsow import *\n",
    "from cvxportfolio.utils import *\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "plotdir='/home/ahmed/cvxportfolio/'\n",
    "datadir='../data/' \n",
    "\n",
    "# consideredInstances=['m4.large', 'm4.xlarge', 'm4.2xlarge', 'r4.large','c5d.9xlarge',\n",
    "#                      'r4.xlarge', 'r4.2xlarge', 'r4.4xlarge', 'r4.8xlarge',  'r5.large']\n",
    "                     #  'r5.2xlarge', 'r5.4xlarge', 'r5.8xlarge', 'r5.12xlarge', 'r5.16xlarge', 'r5.24xlarge', 'r5d.large',\n",
    "                    # 'r5d.xlarge', 'r5d.2xlarge', 'r5d.4xlarge', 'r5d.8xlarge', 'r5d.12xlarge', 'r5d.16xlarge']\n",
    "#                     ,'r4.xlarge','m4.10xlarge', 'r4.4xlarge', 'r4.xlarge', 'r4.2xlarge', 'r4.4xlarge', 'r4.8xlarge', 'r4.16xlarge', 'r5.large', 'r5.xlarge',\n",
    "#                       'r5.2xlarge', 'r5.4xlarge', 'r5.8xlarge', 'r5.12xlarge', 'r5.16xlarge', 'r5.24xlarge', 'r5d.large',\n",
    "#                      'r5d.xlarge', 'r5d.2xlarge', 'r5d.4xlarge', 'r5d.8xlarge', 'r5d.12xlarge', 'r5d.16xlarge',\n",
    "#                       'r5d.24xlarge', 'x1.16xlarge', 'x1.32xlarge',  'c4.large', 'c4.xlarge', 'c4.2xlarge', 'c4.4xlarge',\n",
    "#                       'c4.8xlarge', 'c5.large', 'c5.xlarge', 'c5.2xlarge', 'c5.4xlarge', 'c5.9xlarge', 'c5.18xlarge',\n",
    "#                       'c5d.large', 'c5d.xlarge', 'c5d.2xlarge', 'c5d.4xlarge', 'c5d.9xlarge', 'c5d.18xlarge', 'm5.large',\n",
    "#                      'm5.xlarge', 'm5.2xlarge', 'm5.4xlarge', 'm5.12xlarge', 'm5.24xlarge', 'm5d.large', 'm5d.xlarge',\n",
    "#                      'm5d.2xlarge', 'm5d.4xlarge', 'm5d.12xlarge', 'm5d.24xlarge']\n",
    "consideredInstances=['m4.large', 'm4.xlarge', 'm4.2xlarge', 'm4.4xlarge', 'm4.10xlarge', 'm4.16xlarge', 'r4.large',\n",
    "                     'r4.xlarge', 'r4.2xlarge', 'r4.4xlarge', 'r4.8xlarge', 'r4.16xlarge', 'r5.large', 'r5.xlarge',\n",
    "                       'r5.2xlarge', 'r5.4xlarge', 'r5.8xlarge', 'r5.12xlarge', 'r5.16xlarge', 'r5.24xlarge', 'r5d.large',\n",
    "                      'r5d.xlarge', 'r5d.2xlarge', 'r5d.4xlarge', 'r5d.8xlarge', 'r5d.12xlarge', 'r5d.16xlarge',\n",
    "                       'r5d.24xlarge', 'x1.16xlarge', 'x1.32xlarge',  'c4.large', 'c4.xlarge', 'c4.2xlarge', 'c4.4xlarge',\n",
    "                       'c4.8xlarge', 'c5.large', 'c5.xlarge', 'c5.2xlarge', 'c5.4xlarge', 'c5.9xlarge', 'c5.18xlarge',\n",
    "                       'c5d.large', 'c5d.xlarge', 'c5d.2xlarge', 'c5d.4xlarge', 'c5d.9xlarge', 'c5d.18xlarge', 'm5.large',\n",
    "                      'm5.xlarge', 'm5.2xlarge', 'm5.4xlarge', 'm5.12xlarge', 'm5.24xlarge', 'm5d.large', 'm5d.xlarge',\n",
    "                      'm5d.2xlarge', 'm5d.4xlarge', 'm5d.12xlarge', 'm5d.24xlarge']\n",
    "\n",
    "consideredInstances=['r5d.24xlarge', 'r5.4xlarge', 'r4.4xlarge']\n",
    "\n",
    "start_t=pd.Timestamp(2008,5,17,10)      #Wikipedia workload timespan\n",
    "end_t=pd.Timestamp(2013,10,16,16)\n",
    "\n",
    "#print \"lambda\", Lambda.all\n",
    "\n",
    "L=np.linspace(0,1,21)\n",
    "# print L\n",
    "\n",
    "#print \"start_t\", type(start_t)\n",
    "sigmas=pd.read_csv(datadir+'sigmas.csv.gz',index_col=0,parse_dates=[0]).iloc[:,:-1]   #index_col=Column to use as the row labels of the DataFrame,\n",
    "                                                                                #parse_dates=Which columns to combine to parse the date, \n",
    "                                                                                #iloc[:,:-1] select all columns without last:\n",
    "returns=pd.read_csv(datadir+'returns.csv.gz',index_col=0,parse_dates=[0])\n",
    "\n",
    "#priceReqind=pd.read_csv('../CurrentPricePerReq.csv',index_col=0,parse_dates=[0])\n",
    "\n",
    "#priceReq=pd.read_csv('minmaxPrice.csv',index_col=0,parse_dates=[0])\n",
    "priceReq=pd.read_csv('../CurrentPricePerReq.csv',index_col=0,parse_dates=[0])\n",
    "\n",
    "filteredPriceReq=pd.DataFrame(index=priceReq.index)\n",
    "multiPrice=[]\n",
    "\n",
    "\n",
    "\n",
    "for i in consideredInstances:\n",
    "    if i in priceReq.columns:\n",
    "        filteredPriceReq[i]=priceReq[i]\n",
    "\n",
    "#filteredPriceReq.index=priceReqind.index #[65:130]     \n",
    "#filPriceReq.set_index(priceReq.index)\n",
    "\n",
    "filteredPriceReq.replace(0,1000000,inplace=True)\n",
    "#print filteredPriceReq.all  \n",
    "covariance=filteredPriceReq.corr()\n",
    "covariance=covariance.T.dot(covariance)\n",
    "\n",
    "print covariance.columns\n",
    "consideredInstances=covariance.columns.tolist()\n",
    "print consideredInstances, len(consideredInstances)\n",
    "\n",
    "print filteredPriceReq\n",
    "Lambda=pd.read_csv(datadir+'AggReq.out',index_col=0,parse_dates=[0],names=['time','Requests'], nrows=len(filteredPriceReq.index),skiprows=range(337))  \n",
    "#lambda in my equation \n",
    "#x=[16612878+(random.randint(10000,1000000)) for i in range(Lambda.size)]\n",
    "#Lambda['Requests']=x\n",
    "\n",
    "Lambda.index=filteredPriceReq.index\n",
    "print Lambda.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.9\n",
      "0\n",
      "Number of instances: 3\n",
      "1465\n",
      "DatetimeIndex(['2018-08-30 22:00:00', '2018-09-06 17:00:00',\n",
      "               '2018-09-19 23:00:00', '2018-09-20 22:00:00',\n",
      "               '2018-09-23 00:00:00', '2018-09-23 01:00:00',\n",
      "               '2018-09-23 05:00:00', '2018-09-23 06:00:00',\n",
      "               '2018-09-23 08:00:00', '2018-09-23 09:00:00',\n",
      "               ...\n",
      "               '2018-11-22 15:00:00', '2018-11-22 16:00:00',\n",
      "               '2018-11-22 17:00:00', '2018-11-22 18:00:00',\n",
      "               '2018-11-22 19:00:00', '2018-11-22 20:00:00',\n",
      "               '2018-11-22 21:00:00', '2018-11-22 22:00:00',\n",
      "               '2018-11-22 23:00:00', '2018-11-23 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=1465, freq=None) DatetimeIndex(['2018-08-30 22:00:00', '2018-09-06 17:00:00',\n",
      "               '2018-09-19 23:00:00', '2018-09-20 22:00:00',\n",
      "               '2018-09-23 00:00:00', '2018-09-23 01:00:00',\n",
      "               '2018-09-23 05:00:00', '2018-09-23 06:00:00',\n",
      "               '2018-09-23 08:00:00', '2018-09-23 09:00:00',\n",
      "               ...\n",
      "               '2018-11-22 15:00:00', '2018-11-22 16:00:00',\n",
      "               '2018-11-22 17:00:00', '2018-11-22 18:00:00',\n",
      "               '2018-11-22 19:00:00', '2018-11-22 20:00:00',\n",
      "               '2018-11-22 21:00:00', '2018-11-22 22:00:00',\n",
      "               '2018-11-22 23:00:00', '2018-11-23 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=1465, freq=None) DatetimeIndex(['2018-08-30 22:00:00', '2018-09-06 17:00:00',\n",
      "               '2018-09-19 23:00:00', '2018-09-20 22:00:00',\n",
      "               '2018-09-23 00:00:00', '2018-09-23 01:00:00',\n",
      "               '2018-09-23 05:00:00', '2018-09-23 06:00:00',\n",
      "               '2018-09-23 08:00:00', '2018-09-23 09:00:00',\n",
      "               ...\n",
      "               '2018-11-22 15:00:00', '2018-11-22 16:00:00',\n",
      "               '2018-11-22 17:00:00', '2018-11-22 18:00:00',\n",
      "               '2018-11-22 19:00:00', '2018-11-22 20:00:00',\n",
      "               '2018-11-22 21:00:00', '2018-11-22 22:00:00',\n",
      "               '2018-11-22 23:00:00', '2018-11-23 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=1465, freq=None)\n",
      "(<frame object at 0x7f993028c5a8>, '<ipython-input-9-63d14e39d96d>', 54, '<module>', [u'simulator = ms.MarketSimulator(costs=[simulated_hcost],failures=filteredfailures)    #This is the initialization of the simulator platform\\n'], 0)\n",
      "cost in sim.py <class 'cvxportfolio.Modcostsoldworking.HcostModelServers'> [<cvxportfolio.Modcostsoldworking.HcostModelServers object at 0x7f99346d20d0>]\n"
     ]
    }
   ],
   "source": [
    "import cvxpy\n",
    "print cvxpy.__version__\n",
    "\n",
    "failureP=pd.read_csv('./failureProbaility.csv',parse_dates=[0])#.iloc[:65]\n",
    "#print failureP.all\n",
    "failureP.index=filteredPriceReq.index\n",
    "\n",
    "#print failureP.all\n",
    "\n",
    "filteredfailures=pd.DataFrame(index=filteredPriceReq.index)\n",
    "print filteredfailures.size\n",
    "\n",
    "for i in consideredInstances:\n",
    "    if i in failureP.columns:\n",
    "        filteredfailures[i]=failureP[i]\n",
    "#print filteredfailures.all\n",
    "print \"Number of instances:\", len(filteredfailures.columns)\n",
    "\n",
    "#print \"Lengthsssss\", len(filteredfailures.iloc[:,1]),len(filteredPriceReq.iloc[:,1])\n",
    "\n",
    "# filteredfailures.index=filteredPriceReq.index\n",
    "# print filteredfailures.all\n",
    "\n",
    "price=pd.read_csv(\"../FullCurrentPrice.csv\",index_col=0,parse_dates=[0],skiprows=range(1000))\n",
    "filteredprice=pd.DataFrame(index=price.index)\n",
    "for i in consideredInstances:\n",
    "    if i in price.columns:\n",
    "        filteredprice[i]=price[i]\n",
    "\n",
    "print len(filteredfailures)\n",
    "iportfolio= [random.choice(range(5)) for i in range(len(filteredfailures.columns))]\n",
    "initialportfolio=dict(zip(covariance.columns,[random.choice(range(2)) for i in range(len(filteredfailures))])) #A_0 in my equations\n",
    "w_b = pd.Series(index=consideredInstances, data=1)   \n",
    "#print w_b.all\n",
    "#A pandas Series is created with all values=1 and an index with all the companies in the trading system of returns.columns=The column labels of the DataFrame.\n",
    "                                                                            #Company names should be changed to Machine types\n",
    "w_b/=sum(w_b)          \n",
    "#Summed the series and divided each element by the sum (so all are  still equal)\n",
    "\n",
    "start_t=pd.Timestamp(2018,1,25,17)\n",
    "end_t=pd.Timestamp(2018,12,28,9)\n",
    "\n",
    "for r in consideredInstances:\n",
    "    filteredfailures.loc[:,r]=0.05\n",
    "\n",
    "print Lambda.index, filteredfailures.index, filteredPriceReq.index\n",
    "#simulated_tcost = mc.TcostModelServers(arrival=Lambda, pricePerReq=filteredPriceReq) \n",
    "simulated_hcost = mc.HcostModelServers(penalty=0.02,L=0.02, pricePerReq=filteredPriceReq,  probFail=filteredfailures,arrivalRate=Lambda)  \n",
    "#The penalty and L should change\n",
    "\n",
    "#print type(simulated_hcost), type(simulated_tcost)\n",
    "#print filteredfailures[0].size, filteredprice[0].size,filteredPriceReq[0].size, w_b.size\n",
    "\n",
    "simulator = ms.MarketSimulator(costs=[simulated_hcost],failures=filteredfailures)    #This is the initialization of the simulator platform\n",
    "\n",
    "\n",
    "#Exactly like the simulated values as we are assuming an oracle for now\n",
    "#optimization_tcost = mc.TcostModelServers(arrival=Lambda, pricePerReq=filteredPriceReq) \n",
    "                            \n",
    "optimization_hcost=mc.HcostModelServers(penalty=0.02,L=0.02, pricePerReq=filteredPriceReq, probFail=filteredfailures,arrivalRate=Lambda)\n",
    "\n",
    "risk_model = mr.FullSigma(Sigma=covariance)\n",
    "\n",
    "results={}   #The results dictionary\n",
    "# print Lambda[start_t:end_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_MPO={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPO Coarse search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "\n",
    "import pickle\n",
    "\n",
    "policies={}\n",
    "\n",
    "gamma_risks_coarse=[5,50,100]\n",
    "lookahead=[1,2,4]#,5,6]\n",
    "accuracy=[0.01]# 0.03, 0.05, 0.1,0.2,0.5,1]\n",
    "#gamma_hcosts_coarse=[1,2,5,10,20]\n",
    "# for g in gamma_risks_coarse:\n",
    "for lookahead_period in lookahead:\n",
    "        #print lookahead_period\n",
    "        for acc in accuracy:\n",
    "            print acc\n",
    "            policies[lookahead_period,acc] = mp.MultiPeriodOpt(costs=[5*risk_model, optimization_hcost], \n",
    "                          constraints=[MaxOP(),LongOnly(),MinZ(),MaxZ()],\n",
    "                          trading_times=list(filteredPriceReq.index[(filteredPriceReq.index>=start_t)&\n",
    "                          (filteredPriceReq.index<=end_t)]), lookahead_periods=lookahead_period,accuracy=acc)\n",
    "\n",
    "\n",
    "results_MPO.update({k:v for k,v in zip(policies.keys(),\n",
    "                           simulator.run_multiple_backtest(w_b, start_time = start_t, end_time=end_t, \n",
    "                                          policies=policies.values(),parallel=False))})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RealExp0.5_MPO_L0.02_LA1_10_pen0.02_risk5_mkt36_SPOwithOracle.txt', 'w') as f:\n",
    "    f.write(cap.stdout)\n",
    "print results_MPO.keys()\n",
    "pickle_out = open(\"RealExp0.5_MPO_L0.02_LA1_10_pen0.02_risk5_mkt36_SPOwithOracle.pickle\",\"wb\")\n",
    "pickle.dump(results_MPO, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import pickle\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "\n",
    "\n",
    "objects = []\n",
    "with (open(\"Wiki_Diversify0.5_MPO_L0.02_LA1_10_pen0.02_risk5_mkt36_SPOwithOracle.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "            \n",
    "results_MPO=objects[0]\n",
    "#print results_MPO.keys()\n",
    "#start_t=pd.Timestamp(2018,9,22,0)\n",
    "#print \"ppp\",filteredPriceReq.index\n",
    "filteredfailures.index=range(65)\n",
    "Lambda.index=range(20)\n",
    "filteredPriceReq.index=range(65)\n",
    "\n",
    "data=Lambda.iloc[:20]\n",
    "#data=data.iloc[48:96]\n",
    "fig, ax = plt.subplots()\n",
    "s=sns.lineplot(data=data,ax=ax)\n",
    "ax.legend_.remove()\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Time (hr)\")\n",
    "plt.ylabel(\"Number of Requests (per hr)\")\n",
    "plt.savefig(\"AutoscalingonlyWiki.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "data=filteredfailures.iloc[:20]\n",
    "#data=data.iloc[48:96]\n",
    "s=sns.lineplot(data=data)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Time (hr)\")\n",
    "plt.ylabel(\"failure\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.savefig(\"Zoomedfailures.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "rdata=filteredPriceReq.iloc[:20]\n",
    "fig, ax = plt.subplots()\n",
    "g=sns.lineplot(data=rdata,ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Time (hr)\")\n",
    "plt.ylabel(\"Price per Request\")\n",
    "plt.savefig(\"AutoscalingZoomedPricePerReq.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "u1=results_MPO[(1, 0.01)].u\n",
    "for k in results_MPO:\n",
    "   if k in lookahead:\n",
    "    #  print k\n",
    "      results_MPO[k].summary()\n",
    "      c=results_MPO[k].simulator_HcostModelServers.to_dict()\n",
    "      l=[]\n",
    "      for j in c:\n",
    "          #  print j\n",
    "            l+=c[j].values()\n",
    "      l = [item for item in l if item >= 0]\n",
    "      #print sum(l)/457\n",
    "        \n",
    "#result_df = result_df_coarse.loc[sorted(result_df_coarse.index), sorted(result_df_coarse.columns)]\n",
    "#print results_MPO.keys()\n",
    "u1=results_MPO[(1, 0.01)].u\n",
    "u2=results_MPO[(2, 0.01)].u\n",
    "u4=results_MPO[(4, 0.01)].u\n",
    "#u6=results_MPO[(6, 0.01)].u\n",
    "#u10=results_MPO[(10, 0.01)].u\n",
    "\n",
    "u1.index=range(65)\n",
    "u2.index=range(65)\n",
    "u4.index=range(65)\n",
    "#print u1\n",
    "\n",
    "onDemandPrice={'r4.4xlarge':1.064,'r5d.24xlarge':6.912,'r5.4xlarge':1.008}\n",
    "# onDemandPrice={'m4.2xlarge':0.40 ,'c5d.9xlarge':1.728,'r4.xlarge':0.266 ,\n",
    "#                'r4.2xlarge':0.532,'r4.4xlarge':1.064,'r4.8xlarge':2.128,\n",
    "#                 'r5d.xlarge':0.288, 'm5d.4xlarge':0.904, 'm5.xlarge':0.192, \n",
    "#                'r4.16xlarge':4.256, 'c5d.xlarge':0.192, 'r5d.4xlarge':1.152, \n",
    "#                'x1.16xlarge':6.669, 'r4.4xlarge':1.064, 'c5d.2xlarge':0.384, \n",
    "#                'r5.xlarge':0.252, 'c4.8xlarge':1.591, 'r4.8xlarge':2.128,\n",
    "#                'm5d.12xlarge':2.712, 'c5.4xlarge':0.68, 'c5.large':0.085, \n",
    "#                'm5.2xlarge':0.384, 'c5.2xlarge':0.34, 'c4.4xlarge':0.796, \n",
    "#                'r5.4xlarge':1.008, 'm5.4xlarge':0.768, 'm5d.xlarge':0.226, \n",
    "#                'c5d.9xlarge':1.728 , 'c4.2xlarge':0.398, 'c5.xlarge':0.17,\n",
    "#                'c5d.4xlarge':0.768, 'c5.9xlarge':1.53, 'r5d.24xlarge':6.912,\n",
    "#                'm5.12xlarge':2.304, 'm5d.2xlarge':0.452, 'r5.2xlarge':0.504,\n",
    "#               'm4.10xlarge':2, 'm4.16xlarge':3.2, 'm4.4xlarge':0.80}\n",
    "# print len(onDemandPrice)\n",
    "capacity=pd.read_csv(\"requestsCapacity.csv\",index_col=0)\n",
    "servers=u1.columns.tolist()\n",
    "#print list(set(servers) - set(onDemandPrice.keys()))\n",
    "print servers\n",
    "capacity=capacity.loc[servers]\n",
    "# print capacity\n",
    "capacity*=3600\n",
    "#price=price.loc[servers]\n",
    "price=pd.read_csv(\"../FullCurrentPrice.csv\",index_col=0,parse_dates=[0])\n",
    "price= price.iloc[500:565]\n",
    "price=price[servers]\n",
    "price.index=filteredfailures.index\n",
    "pricediv=price/onDemandPrice\n",
    "#print price\n",
    "\n",
    "u1[u1 < 0] = 0\n",
    "u2[u2 < 0] = 0\n",
    "u4[u4 < 0] = 0\n",
    "#u6[u6 < 0] = 0\n",
    "#u10[u10 < 0] = 0\n",
    "\n",
    "#print u1\n",
    "Lambda=Lambda.iloc[:20]\n",
    "#print Lambda\n",
    "#print u1, Lambda.Requests\n",
    "u2=u2.multiply(Lambda['Requests'],axis='index')\n",
    "u1=u1.multiply(Lambda['Requests'],axis='index')\n",
    "u4=u4.multiply(Lambda['Requests'],axis='index')\n",
    "\n",
    "\n",
    "for s in servers:\n",
    "    #print u2[s]\n",
    "    print capacity.loc[s].tolist()[0]\n",
    "    u1[s]=u1[s]/capacity.loc[s].tolist()[0]\n",
    "    u2[s]=u2[s]/capacity.loc[s].tolist()[0]\n",
    "    u4[s]=u4[s]/capacity.loc[s].tolist()[0]\n",
    "\n",
    "# u1.index=range(85)\n",
    "# u2.index=range(85)\n",
    "# u4.index=range(85)\n",
    "# print u1\n",
    "    \n",
    "u2= u2.iloc[:20].round()\n",
    "u1=u1.iloc[:20].round()\n",
    "u4=u4.iloc[:20].round()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "g=sns.lineplot(data=u1,ax=ax)\n",
    "ax.legend_.remove()\n",
    "plt.axvline(x=2, color='k', linestyle='--')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Time (hr)\")\n",
    "plt.ylabel(\"Allocation to total Capacity\")\n",
    "plt.savefig(\"AutoScalingOnlyZoomedAllocSPO.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "g=sns.lineplot(data=u2,ax=ax)\n",
    "ax.legend_.remove()\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Time (hr)\")\n",
    "plt.ylabel(\"Allocation to total Capacity\")\n",
    "plt.savefig(\"AutoScalingOnlyZoomedAllocMPO.pdf\", bbox_inches='tight',legend=False)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "g=sns.lineplot(data=u2-u1,ax=ax)\n",
    "ax.legend_.remove()\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Time (hr)\")\n",
    "plt.ylabel(\"Delta machines\")\n",
    "plt.savefig(\"AutoScalingOnlyZoomedAllocDiff.pdf\", bbox_inches='tight',legend=False)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# g=sns.lineplot(data=u4-u2)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Delta machines\")\n",
    "# plt.savefig(\"ZoomedAlloc_Look1_0_3.pdf\", bbox_inches='tight')\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "g=sns.lineplot(data=(u2.multiply(price)).div(u2.multiply(onDemandPrice)),ax=ax)\n",
    "#ax.legend_.remove()\n",
    "plt.xticks(rotation=45)\n",
    "ax.legend(bbox_to_anchor=(0.9, 0.7))\n",
    "plt.xlabel(\"Time (hr)\")\n",
    "plt.ylabel(\"Cost compared to on-demand\")\n",
    "plt.savefig(\"ِAutoScalingOnlyZoomedCostReductionToOnDemand.pdf\", bbox_inches='tight',legend=False)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print u1.multiply(price).fillna(0).values.sum()/ u1.multiply(onDemandPrice).fillna(0).values.sum()\n",
    "print u2.multiply(price).fillna(0).values.sum()/ u2.multiply(onDemandPrice).fillna(0).values.sum()\n",
    "print u2.multiply(price).fillna(0).values.sum()/ u1.multiply(price).fillna(0).values.sum()\n",
    "\n",
    "# g=sns.lineplot(data=u4)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Allocation to total Capacity\")\n",
    "# plt.savefig(\"ZoomedAlloc_Look1_0_3.pdf\", bbox_inches='tight')\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print policies.keys()\n",
    "result_df_coarse=pd.DataFrame()\n",
    "if k[0] in gamma_risks_coarse and k[1] in gamma_tcosts_coarse:\n",
    "       result_df_coarse.loc[k[0], k[1]] = results_MPO[k]\n",
    "        \n",
    "result_df = result_df_coarse.loc[sorted(result_df_coarse.index), sorted(result_df_coarse.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "for gamma_tcost in result_df.columns:\n",
    "    x=[el.excess_returns.std()*100*np.sqrt(250) for el in result_df[gamma_tcost]]\n",
    "    y=[el.excess_returns.mean()*100*250 for el in result_df[gamma_tcost]]\n",
    "    plt.plot(np.array(x),np.array(y), '.-', label='$\\gamma^\\mathrm{trade} = %g$'%gamma_tcost)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Risk')\n",
    "plt.ylabel('Return')\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0,30])\n",
    "\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f%%'))\n",
    "ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f%%'))\n",
    "\n",
    "plt.savefig(plotdir+'mpo_riskrewardfrontier.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPO Pareto search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pareto={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policies={}\n",
    "#gamma_risks_pareto=[int(round(el)) for el in np.logspace(0,3,13)]\n",
    "gamma_risks_pareto=[1, 2, 3, 6, 10, 18, 32, 56, 100, 178, 316, 562, 1000]\n",
    "gamma_tcosts_pareto=[7,8,9,10,11,12]\n",
    "gamma_holdings=[.1,1.,10., 100.,1000.]\n",
    "for gamma_risk in gamma_risks_pareto:\n",
    "    for gamma_tcost in gamma_tcosts_pareto : \n",
    "        for gamma_holding in gamma_holdings:\n",
    "            policies[(gamma_risk, gamma_tcost, gamma_holding)] = \\\n",
    "      cp.MultiPeriodOpt(alpha_model=returns_forecast, \n",
    "                          costs=[gamma_risk*risk_model, gamma_tcost*optimization_tcost, \n",
    "                                 gamma_holding*optimization_hcost], \n",
    "                          constraints=[cp.LeverageLimit(3)],\n",
    "                          trading_times=list(returns.index[(returns.index>=start_t)&(returns.index<=end_t)]),\n",
    "                         lookahead_periods=2,\n",
    "                         terminal_weights=None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "results_pareto.update(dict(zip(policies.keys(), simulator.run_multiple_backtest(1E8*w_b, start_time=start_t,\n",
    "                                                                                end_time=end_t,\n",
    "                                              policies=policies.values(), parallel=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.DataFrame()\n",
    "table[r'$\\gamma^\\mathrm{risk}$']=[el[0] for el in results_pareto.keys()]\n",
    "table[r'$\\gamma^\\mathrm{trade}$']=[el[1] for el in results_pareto.keys()]\n",
    "table[r'$\\gamma^\\mathrm{hold}$']=['%g'%el[2] for el in results_pareto.keys()]\n",
    "table['Return']=[(results_pareto[k].excess_returns.mean()*100*250) for k in results_pareto.keys()]\n",
    "table['Risk']=[(results_pareto[k].excess_returns.std()*100*np.sqrt(250)) for k in results_pareto.keys()]\n",
    "\n",
    "table = table.sort_values('Risk', ascending=False).reset_index()\n",
    "del table['index']\n",
    "is_pareto = lambda i: table.loc[i,'Return']>=max(table.ix[i:].Return)\n",
    "table['is_pareto'] = [is_pareto(i) for i in range(len(table))]\n",
    "table.to_csv(datadir+'mpo_pareto_results.csv', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(table.Risk.values,table.Return.values)\n",
    "plt.plot(table[table.is_pareto].Risk,table[table.is_pareto].Return, 'C1.-', label='Pareto optimal frontier')\n",
    "plt.legend( loc='lower right')\n",
    "plt.xlabel('Risk')\n",
    "plt.ylabel('Return')\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0,30])\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f%%'))\n",
    "ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f%%'))\n",
    "\n",
    "plt.savefig(plotdir+'mpo_pareto.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim=20\n",
    "ylim=30\n",
    "tableprint=table[table.is_pareto]\n",
    "tableprint=tableprint[tableprint.Risk <= xlim]\n",
    "tableprint=tableprint[tableprint.Return <= ylim]\n",
    "del tableprint['is_pareto']\n",
    "tableprint.Risk=tableprint.Risk.apply(lambda x: '%.2f%%'%x)\n",
    "tableprint.Return=tableprint.Return.apply(lambda x: '%.2f%%'%x)\n",
    "print(tableprint.iloc[::-1].to_latex(float_format='%.2f', escape=False, index=False).replace('%',r'\\%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SPO vs MPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_spo = pd.read_csv('spo_pareto_results.csv', index_col=0)\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "plt.plot(table[table.is_pareto].Risk,table[table.is_pareto].Return, 'C3.-', label='MPO pareto frontier')\n",
    "plt.plot(table_spo[table_spo.is_pareto].Risk,\n",
    "         table_spo[table_spo.is_pareto].Return, 'C2.-', label='SPO pareto frontier')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Risk')\n",
    "plt.ylabel('Return')\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0,30])\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f%%'))\n",
    "ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f%%'))\n",
    "\n",
    "\n",
    "plt.savefig(plotdir+'spo_vs_mpo_pareto.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
